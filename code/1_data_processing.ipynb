{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddd1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext rpy2.ipython\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "import utils\n",
    "import visualizations\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89f8c2",
   "metadata": {},
   "source": [
    "## 1. Pre-processing and Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278be174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0625_095113] In total: 489 rows\n",
      "[0625_095113] NoVideo: 124 rows\n",
      "[0625_095113] Machines: 121 rows\n",
      "[0625_095113] Tools: 122 rows\n",
      "[0625_095113] Companions: 122 rows\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"NoVideo\", \"Machines\", \"Tools\", \"Companions\"]\n",
    "\n",
    "baseline_df_path = '../data/raw/baseline_raw_data.csv'\n",
    "experimental_df_path = '../data/raw/experimental_raw_data.csv'\n",
    "\n",
    "baseline_df = utils.read_file(baseline_df_path)\n",
    "experimental_df = utils.read_file(experimental_df_path)\n",
    "\n",
    "# Make 'Finished' column all upper case and select data rows that are completed\n",
    "baseline_df['Finished'] = baseline_df['Finished'].str.upper()\n",
    "experimental_df['Finished'] = experimental_df['Finished'].str.upper()\n",
    "\n",
    "# Only select finished rows\n",
    "baseline_df = baseline_df[baseline_df['Finished'] == 'TRUE']\n",
    "experimental_df = experimental_df[experimental_df['Finished'] == 'TRUE']\n",
    "# Merge baseline and experimental conditions data\n",
    "df = pd.merge(baseline_df, experimental_df, how='outer')\n",
    "\n",
    "utils.informal_log(\"In total: {} rows\".format(len(df)))\n",
    "\n",
    "# Print # rows in each condition\n",
    "utils.informal_log(\"NoVideo: {} rows\".format(len(baseline_df)))\n",
    "utils.informal_log(\"Machines: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Mechanistic'])))\n",
    "utils.informal_log(\"Tools: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Functional'])))\n",
    "utils.informal_log(\"Companions: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Intentional'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedb7de",
   "metadata": {},
   "source": [
    "## Make Save Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc75ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0625_095339] Parent save directory: ../analysis\n",
      "[0625_095339] Timing save directory: ../analysis/timings\n",
      "[0625_095339] Demographics save directory: ../analysis/demographics\n",
      "[0625_095339] Mental capacity save directory: ../analysis/mental_capacities\n",
      "[0625_095339] Mental capacity ratings statistics save directory: ../analysis/mental_capacities/statistics\n",
      "[0625_095339] Body-heart-mind save dir: ../analysis/mental_capacities/body-heart-mind\n",
      "[0625_095339] Exploratory save directory: ../analysis/exploratory\n"
     ]
    }
   ],
   "source": [
    "# Exclusion parameters\n",
    "min_survey_time = round(80 / 60, 4) # ~80 seconds\n",
    "min_median_per_page_time = round(1 / 60, 4) # ~1 second\n",
    "post_attention_check = True\n",
    "\n",
    "'''\n",
    "Commonly used Paths/Items\n",
    "'''\n",
    "PATH_TO_ROOT = '..'\n",
    "overwrite = False\n",
    "items_path = os.path.join(PATH_TO_ROOT, 'data/files/mental_capacity_items.txt')\n",
    "categories_path = os.path.join(PATH_TO_ROOT, 'data/files/category_groupings.json')\n",
    "save_ext = 'pdf' # File extension for saving visualizations\n",
    "separate_groups = False  # If True, create separate CSV for items of different groups for analysis\n",
    "\n",
    "'''\n",
    "Save dirs\n",
    "'''\n",
    "\n",
    "# Make save directory\n",
    "save_dir = os.path.join(PATH_TO_ROOT, 'analysis')\n",
    "utils.ensure_dir(save_dir)\n",
    "utils.informal_log(\"Parent save directory: {}\".format(save_dir))\n",
    "\n",
    "# Timing save dir\n",
    "time_save_dir = os.path.join(save_dir, 'timings')\n",
    "utils.ensure_dir(time_save_dir)\n",
    "utils.informal_log(\"Timing save directory: {}\".format(time_save_dir))\n",
    "\n",
    "# Demographics post-exclusions\n",
    "demographics_save_dir = os.path.join(save_dir, 'demographics')\n",
    "utils.ensure_dir(demographics_save_dir)\n",
    "utils.informal_log(\"Demographics save directory: {}\".format(demographics_save_dir))\n",
    "\n",
    "# Ratings CSV save dir\n",
    "ratings_save_dir = os.path.join(save_dir, 'mental_capacities')\n",
    "ratings_path = os.path.join(ratings_save_dir, 'ratings.csv')\n",
    "utils.ensure_dir(ratings_save_dir)\n",
    "utils.informal_log(\"Mental capacity save directory: {}\".format(ratings_save_dir))\n",
    "\n",
    "# Rating statistics save directory\n",
    "rating_stats_save_dir = os.path.join(ratings_save_dir, 'statistics')\n",
    "utils.ensure_dir(rating_stats_save_dir)\n",
    "utils.informal_log(\"Mental capacity ratings statistics save directory: {}\".format(rating_stats_save_dir))\n",
    "\n",
    "# R CSV save dir for Body Heart Mind\n",
    "bhm_save_dir = os.path.join(ratings_save_dir, 'body-heart-mind')\n",
    "utils.ensure_dir(bhm_save_dir)\n",
    "utils.informal_log(\"Body-heart-mind save dir: {}\".format(bhm_save_dir))\n",
    "\n",
    "R_input_dir = os.path.join(bhm_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(R_input_dir)\n",
    "\n",
    "# R results save dir for Body Heart Mind\n",
    "R_results_save_dir = os.path.join(ratings_save_dir, 'body-heart-mind', 'R', 'results')\n",
    "utils.ensure_dir(R_results_save_dir)\n",
    "\n",
    "# Save dir for factor analysis\n",
    "fa_save_dir = os.path.join(ratings_save_dir, 'factor_analysis')\n",
    "utils.ensure_dir(fa_save_dir)\n",
    "\n",
    "# Save dir for k-fold factor analysis\n",
    "fa_kfold_save_dir = os.path.join(fa_save_dir, 'kfold')\n",
    "utils.ensure_dir(fa_kfold_save_dir)\n",
    "\n",
    "# Save dir for factor analysis results\n",
    "fa_results_save_dir = os.path.join(fa_save_dir, 'results')\n",
    "utils.ensure_dir(fa_results_save_dir)\n",
    "\n",
    "# Save dir for R analysis based on factor loading groupings\n",
    "fa_R_input_dir = os.path.join(fa_results_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(fa_R_input_dir)\n",
    "\n",
    "# Save dir for R analysis output based on factor loading groupings\n",
    "fa_R_results_dir = os.path.join(fa_results_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(fa_R_results_dir)\n",
    "\n",
    "# BHM Mentioned/Unmentioned save dir\n",
    "bhm_mentioned_save_dir = os.path.join(bhm_save_dir, 'mentioned_analysis')\n",
    "utils.ensure_dir(bhm_mentioned_save_dir)\n",
    "\n",
    "bhm_mentioned_R_csv_save_dir = os.path.join(bhm_mentioned_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(bhm_mentioned_R_csv_save_dir)\n",
    "\n",
    "bhm_mentioned_R_result_save_dir = os.path.join(bhm_mentioned_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(bhm_mentioned_R_result_save_dir)\n",
    "\n",
    "# FA Mentioned/Unmentioned save dir\n",
    "fa_mentioned_save_dir = os.path.join(fa_save_dir, 'mentioned_analysis')\n",
    "utils.ensure_dir(fa_mentioned_save_dir)\n",
    "\n",
    "fa_mentioned_R_csv_save_dir = os.path.join(fa_mentioned_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(fa_mentioned_R_csv_save_dir)\n",
    "\n",
    "fa_mentioned_R_result_save_dir = os.path.join(fa_mentioned_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(fa_mentioned_R_result_save_dir)\n",
    "\n",
    "# item-level analyses with R save dir\n",
    "item_level_save_dir = os.path.join(ratings_save_dir, 'item_level')\n",
    "utils.ensure_dir(item_level_save_dir)\n",
    "\n",
    "# Attitudes save dir\n",
    "attitudes_save_dir = os.path.join(save_dir, 'attitudes')\n",
    "utils.ensure_dir(attitudes_save_dir)\n",
    "\n",
    "# Attitudes R CSV save dir\n",
    "addit_dv_r_csv_save_dir = os.path.join(attitudes_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(addit_dv_r_csv_save_dir)\n",
    "\n",
    "# Attitudes R results save dir\n",
    "addit_dv_r_result_save_dir = os.path.join(attitudes_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(addit_dv_r_result_save_dir)\n",
    "\n",
    "# Exploratory analysis save dir\n",
    "exploratory_save_dir = os.path.join(save_dir, 'exploratory')\n",
    "utils.informal_log(\"Exploratory save directory: {}\".format(exploratory_save_dir))\n",
    "\n",
    "# Attitudes Correlations save dir\n",
    "correlation_dir = os.path.join(exploratory_save_dir, 'correlations')\n",
    "utils.ensure_dir(correlation_dir)\n",
    "\n",
    "# Reliability save dir\n",
    "reliability_save_dir = os.path.join(exploratory_save_dir, 'reliability')\n",
    "utils.ensure_dir(reliability_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c2c8d",
   "metadata": {},
   "source": [
    "### Timing Analysis\n",
    "\n",
    "We utilize this information in order to filter out participants who spend too little time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d442b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure to map individual questions to sections of the survey\n",
    "time_mapping = {\n",
    "    'intro': {\n",
    "        'ConsentTime1': 'consent_time',\n",
    "        'PS4': 'screening_time',\n",
    "        'Q10': 'instructions_time',\n",
    "        'Q12': 'check_time',\n",
    "    },\n",
    "    'video': {\n",
    "        # Videos\n",
    "        'Q14': 'mech1_time',\n",
    "        'Q16': 'mech2_time',\n",
    "        'Q18': 'mech3_time',\n",
    "        'Q20': 'func1_time',\n",
    "        'Q22': 'func2_time',\n",
    "        'Q24': 'func3_time',\n",
    "        'Q26': 'intent1_time',\n",
    "        'Q28': 'intent2_time',\n",
    "        'Q30': 'intent3_time',\n",
    "\n",
    "    },\n",
    "    'video_transition': {\n",
    "        # Video -> Survey Transition\n",
    "        'Q32': 'takeaways_time',\n",
    "        'Q34': 'transition_time',\n",
    "    },\n",
    "    'survey': {\n",
    "        # Survey\n",
    "        'Q36': 'survey_time'\n",
    "    },\n",
    "    'post': {\n",
    "        # 'CTime1': 'confidence_time',\n",
    "        'ACTime1': 'attention_check_time',\n",
    "        'DVTime1': 'addit_dvs1_time',\n",
    "        'DVTime2': 'addit_dvs2_time',\n",
    "        'Q42': 'mech_conceptual_time',\n",
    "        'DQTime1': 'demographic_time',\n",
    "        'Q44': 'intent_eos_time',\n",
    "        'Q46': 'eos_time'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_column_mapping = {\n",
    "    'Duration (in seconds)': 'total_time',\n",
    "    'CONDITION': 'condition',\n",
    "    'ResponseId': 'response_id',\n",
    "    'PROLIFIC_PID': 'prolific_id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a67e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file to ../analysis/timings/anthro_survey_time.csv\n",
      "Saved file to ../analysis/timings/time_analysis_all_minutes.csv\n",
      "Saved file to ../analysis/timings/timing_stats_all_minutes.csv\n",
      "File at ../analysis/timings/anthro_survey_time.csv exists and not overwriting\n",
      "[0625_095341] Column Q42_Page Submit (post_mech_conceptual_time) not in DF columns in baseline condition\n",
      "[0625_095341] Column Q44_Page Submit (post_intent_eos_time) not in DF columns in baseline condition\n",
      "Saved file to ../analysis/timings/time_analysis_baseline_minutes.csv\n",
      "Saved file to ../analysis/timings/timing_stats_baseline_minutes.csv\n",
      "File at ../analysis/timings/anthro_survey_time.csv exists and not overwriting\n",
      "Saved file to ../analysis/timings/time_analysis_exp_minutes.csv\n",
      "Saved file to ../analysis/timings/timing_stats_exp_minutes.csv\n",
      "[0625_095341] Added time columns to DF (489 rows)\n",
      "Saved file to ../analysis/raw_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Time analysis on all data (baseline + experimental)\n",
    "time_df = analysis.time_analysis(\n",
    "    df=df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='all',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "time_stats_df = analysis.time_stats(\n",
    "    time_df=time_df,\n",
    "    condition='all',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Time analysis on baseline data\n",
    "baseline_time_df = analysis.time_analysis(\n",
    "    df=baseline_df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='baseline',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "baseline_time_stats_df = analysis.time_stats(\n",
    "    time_df=baseline_time_df,\n",
    "    condition='baseline',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Time analysis on experimental data\n",
    "experimental_time_df = analysis.time_analysis(\n",
    "    df=experimental_df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='exp',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "experimental_time_stats_df = analysis.time_stats(\n",
    "    time_df=experimental_time_df,\n",
    "    condition='exp',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Append each user's time in raw dataframe\n",
    "if 'survey_time' not in df.columns:\n",
    "    df = pd.concat([df, time_df['survey']], axis=1)\n",
    "    df = df.rename(columns={'survey': 'survey_time'})\n",
    "    df = pd.concat([df, time_df[['median_time_per_survey_page', 'min_time_per_survey_page', 'max_time_per_survey_page']]], axis=1)\n",
    "\n",
    "    utils.informal_log(\"Added time columns to DF ({} rows)\".format(len(df)))\n",
    "raw_df_save_path = os.path.join(save_dir, 'raw_df.csv')\n",
    "utils.write_file(df, raw_df_save_path, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a569cd",
   "metadata": {},
   "source": [
    "## Perform Exclusions\n",
    "Exclude participants who meet any of the pre-registered criteria:\n",
    "\n",
    "Fail attention check\n",
    "Spend less than 80 second on mental capacity survey\n",
    "Spend less than 1 second per mental capacity question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7fa339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0625_095343] 476 rows remaining post filtering for minimum of 1.3333 minutes on survey\n",
      "[0625_095343] 476 rows remaining post filtering for minimum median of 0.0167 minutes on each survey page\n",
      "[0625_095343] 470 rows remaining post filtering for post-survey attention check correctness\n",
      "[0625_095343] No manual exclusions performed\n",
      "[0625_095343] Number of rows: 470\n",
      "[0625_095343] Number of rows in novideo (baseline): 118\n",
      "[0625_095343] Number of rows in machines: 116\n",
      "[0625_095343] Number of rows in tools: 119\n",
      "[0625_095343] Number of rows in companions: 117\n",
      "Saved file to ../analysis/mental_capacities/post_exclusion_df.csv\n",
      "Saved file to ../analysis/mental_capacities/exclusion_params.json\n"
     ]
    }
   ],
   "source": [
    "# Get DF post exclusions\n",
    "post_exclusion_df = analysis.perform_exclusions(\n",
    "    df=df,\n",
    "    min_survey_time=min_survey_time,\n",
    "    min_median_per_page_time=min_median_per_page_time,\n",
    "    manual_exclusions=None,\n",
    "    post_attention_check=post_attention_check)\n",
    "\n",
    "exclusion_params = {\n",
    "    'min_survey_time': min_survey_time,\n",
    "    'min_median_per_page_time': min_median_per_page_time,\n",
    "    'n_rows': len(post_exclusion_df)\n",
    "}\n",
    "\n",
    "post_exclusion_df_save_path = os.path.join(ratings_save_dir, 'post_exclusion_df.csv')\n",
    "utils.write_file(post_exclusion_df, post_exclusion_df_save_path, overwrite=overwrite)\n",
    "\n",
    "exclusion_param_save_path = os.path.join(ratings_save_dir, 'exclusion_params.json')\n",
    "if os.path.exists(exclusion_param_save_path):\n",
    "    utils.informal_log(\"Exclusion parameters already exist at {}. Meaning this directory contains some exclusion configuration. Save to another directory\".format(\n",
    "        exclusion_param_save_path\n",
    "    ))\n",
    "else:\n",
    "    utils.write_file(exclusion_params, exclusion_param_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d266d5b",
   "metadata": {},
   "source": [
    "## Demographic Data\n",
    "Obtain demographic data post exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a8107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0625_095344] Saving demographics to ../analysis/demographics/demographics.csv\n",
      "Saved file to ../analysis/demographics/demographics.csv\n"
     ]
    }
   ],
   "source": [
    "demographic_qs = {\n",
    "    'DQ2': 'age',\n",
    "    'DQ3': 'education',\n",
    "    'DQ4': 'gender',\n",
    "    'DQ5': 'race',\n",
    "    'DQ6': 'ethnicity',\n",
    "    'DQ7': 'religion',\n",
    "    'DQ9': 'programming',\n",
    "    'DQ10_1': 'familiarity_chatgpt',\n",
    "    'DQ10_2': 'familiarity_gemini',\n",
    "    'DQ10_3': 'familiarity_claude',\n",
    "    'DQ10_4': 'familiarity_copilot',\n",
    "    'DQ10_5': 'familiarity_replika',\n",
    "    'DQ10_6': 'familiarity_nomi',\n",
    "    'DQ10_7': 'familiarity_characterai'\n",
    "}\n",
    "\n",
    "analysis.get_demographics(\n",
    "    df=post_exclusion_df,\n",
    "    demographic_qs=demographic_qs,\n",
    "    save_dir=demographics_save_dir,\n",
    "    overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5e791",
   "metadata": {},
   "source": [
    "## Clean data to obtain dataframe of ratings\n",
    "Filter out other information besides participant's ratings on each of the 40 mental capacity items, condition, and prolificID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9b459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file to ../analysis/mental_capacities/ratings.csv\n",
      "[0625_095346] Rating DF stats:\n",
      "[0625_095346] Number of rows: 470\n",
      "[0625_095346] Number of rows in baseline: 118\n",
      "[0625_095346] Number of rows in mechanistic: 116\n",
      "[0625_095346] Number of rows in functional: 119\n",
      "[0625_095346] Number of rows in intentional: 117\n",
      "Saved file to ../analysis/mental_capacities/statistics/rating_stats.csv\n",
      "Saved file to ../analysis/mental_capacities/statistics/novideo_rating_stats.csv\n",
      "Saved file to ../analysis/mental_capacities/statistics/machines_rating_stats.csv\n",
      "Saved file to ../analysis/mental_capacities/statistics/tools_rating_stats.csv\n",
      "Saved file to ../analysis/mental_capacities/statistics/companions_rating_stats.csv\n",
      "Saved file to ../analysis/mental_capacities/statistics/all_conditions_ratings_stats.csv\n"
     ]
    }
   ],
   "source": [
    "items = utils.read_file(items_path)\n",
    "groupings = utils.read_file(categories_path)\n",
    "n_pages = 40 # Number of survey pages for mental capacity\n",
    "n_items_per_page = 1\n",
    "q_id = 'Q35'\n",
    "n_total = n_pages * n_items_per_page\n",
    "columns = df.columns\n",
    "\n",
    "# MC = mental capacity\n",
    "mc_mapping = analysis.get_mc_mapping(\n",
    "    items=items,\n",
    "    n_pages=n_pages,\n",
    "    n_items_per_page=n_items_per_page,\n",
    "    q_id=q_id,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# Make dataframe of ratings (rows = participants; columns = mental states)\n",
    "rating_df = analysis.get_ratings(\n",
    "    df=post_exclusion_df,\n",
    "    mc_mapping=mc_mapping,\n",
    "    groupings=groupings,\n",
    "    n_total=n_total,\n",
    "    save_dir=ratings_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Get mean (and std) ratings of each mental state in separate dataframes for each condition\n",
    "stats_dfs = analysis.mean_ratings(\n",
    "    rating_df=rating_df,\n",
    "    conditions=conditions,\n",
    "    save_conditions=True,\n",
    "    save_dir=rating_stats_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Combine list of stats for each condition into one large DF\n",
    "master_stats = analysis.create_master_stats(\n",
    "    stats_dfs=stats_dfs,\n",
    "    save_dir=rating_stats_save_dir,\n",
    "    overwrite=overwrite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiexhibit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
