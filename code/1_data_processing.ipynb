{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddd1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext rpy2.ipython\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "import utils\n",
    "import visualizations\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89f8c2",
   "metadata": {},
   "source": [
    "## 1. Pre-processing and Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278be174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_145343] In total: 489 rows\n",
      "[0624_145343] NoVideo: 124 rows\n",
      "[0624_145343] Machines: 121 rows\n",
      "[0624_145343] Tools: 122 rows\n",
      "[0624_145343] Companions: 122 rows\n"
     ]
    }
   ],
   "source": [
    "conditions = [\"NoVideo\", \"Machines\", \"Tools\", \"Companions\"]\n",
    "\n",
    "baseline_df_path = '../data/raw/baseline_raw_data.csv'\n",
    "experimental_df_path = '../data/raw/experimental_raw_data.csv'\n",
    "\n",
    "baseline_df = utils.read_file(baseline_df_path)\n",
    "experimental_df = utils.read_file(experimental_df_path)\n",
    "\n",
    "# Make 'Finished' column all upper case and select data rows that are completed\n",
    "baseline_df['Finished'] = baseline_df['Finished'].str.upper()\n",
    "experimental_df['Finished'] = experimental_df['Finished'].str.upper()\n",
    "\n",
    "# Only select finished rows\n",
    "baseline_df = baseline_df[baseline_df['Finished'] == 'TRUE']\n",
    "experimental_df = experimental_df[experimental_df['Finished'] == 'TRUE']\n",
    "# Merge baseline and experimental conditions data\n",
    "df = pd.merge(baseline_df, experimental_df, how='outer')\n",
    "\n",
    "utils.informal_log(\"In total: {} rows\".format(len(df)))\n",
    "\n",
    "# Print # rows in each condition\n",
    "utils.informal_log(\"NoVideo: {} rows\".format(len(baseline_df)))\n",
    "utils.informal_log(\"Machines: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Mechanistic'])))\n",
    "utils.informal_log(\"Tools: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Functional'])))\n",
    "utils.informal_log(\"Companions: {} rows\".format(len(experimental_df[experimental_df['CONDITION'] == 'Intentional'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedb7de",
   "metadata": {},
   "source": [
    "## Make Save Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc75ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_145413] Parent save directory: ../analysis\n",
      "[0624_145413] Timing save directory: ../analysis/timings\n",
      "[0624_145413] Demographics save directory: ../analysis/demographics\n",
      "[0624_145413] Mental capacity save directory: ../analysis/mental_capacities\n",
      "[0624_145413] Mental capacity ratings statistics save directory: ../analysis/mental_capacities/statistics\n",
      "[0624_145413] Correlations save directory: ../analysis/mental_capacities\n"
     ]
    }
   ],
   "source": [
    "# Exclusion parameters\n",
    "min_survey_time = round(80 / 60, 4) # ~80 seconds\n",
    "min_median_per_page_time = round(1 / 60, 4) # ~1 second\n",
    "post_attention_check = True\n",
    "\n",
    "'''\n",
    "Commonly used Paths/Items\n",
    "'''\n",
    "PATH_TO_ROOT = '..'\n",
    "overwrite = False\n",
    "items_path = os.path.join(PATH_TO_ROOT, 'data/files/mental_capacity_items.txt')\n",
    "categories_path = os.path.join(PATH_TO_ROOT, 'data/files/category_groupings.json')\n",
    "save_ext = 'pdf' # File extension for saving visualizations\n",
    "separate_groups = False  # If True, create separate CSV for items of different groups for analysis\n",
    "\n",
    "'''\n",
    "Save dirs\n",
    "'''\n",
    "\n",
    "# Make save directory\n",
    "save_dir = os.path.join(PATH_TO_ROOT, 'analysis')\n",
    "utils.ensure_dir(save_dir)\n",
    "utils.informal_log(\"Parent save directory: {}\".format(save_dir))\n",
    "\n",
    "# Timing save dir\n",
    "time_save_dir = os.path.join(save_dir, 'timings')\n",
    "utils.ensure_dir(time_save_dir)\n",
    "utils.informal_log(\"Timing save directory: {}\".format(time_save_dir))\n",
    "\n",
    "# Demographics post-exclusions\n",
    "demographics_save_dir = os.path.join(save_dir, 'demographics')\n",
    "utils.ensure_dir(demographics_save_dir)\n",
    "utils.informal_log(\"Demographics save directory: {}\".format(demographics_save_dir))\n",
    "\n",
    "# Ratings CSV save dir\n",
    "ratings_save_dir = os.path.join(save_dir, 'mental_capacities')\n",
    "ratings_path = os.path.join(ratings_save_dir, 'ratings.csv')\n",
    "utils.ensure_dir(ratings_save_dir)\n",
    "utils.informal_log(\"Mental capacity save directory: {}\".format(ratings_save_dir))\n",
    "\n",
    "# Rating statistics save directory\n",
    "rating_stats_save_dir = os.path.join(ratings_save_dir, 'statistics')\n",
    "utils.ensure_dir(rating_stats_save_dir)\n",
    "utils.informal_log(\"Mental capacity ratings statistics save directory: {}\".format(rating_stats_save_dir))\n",
    "\n",
    "# Participant Correlation save dir\n",
    "corr_save_dir = os.path.join(save_dir, 'correlations')\n",
    "utils.ensure_dir(corr_save_dir)\n",
    "utils.informal_log(\"Correlations save directory: {}\".format(ratings_save_dir))\n",
    "\n",
    "# R CSV save dir for Body Heart Mind\n",
    "R_input_dir = os.path.join(ratings_save_dir, 'body-heart-mind', 'R', 'input_files')\n",
    "utils.ensure_dir(R_input_dir)\n",
    "\n",
    "# R results save dir for Body Heart Mind\n",
    "R_results_save_dir = os.path.join(ratings_save_dir, 'body-heart-mind', 'R', 'results')\n",
    "utils.ensure_dir(R_results_save_dir)\n",
    "\n",
    "# Save dir for factor analysis\n",
    "fa_save_dir = os.path.join(ratings_save_dir, 'factor_analysis')\n",
    "utils.ensure_dir(fa_save_dir)\n",
    "\n",
    "# Save dir for k-fold factor analysis\n",
    "fa_kfold_save_dir = os.path.join(fa_save_dir, 'kfold')\n",
    "utils.ensure_dir(fa_kfold_save_dir)\n",
    "\n",
    "# Save dir for factor analysis results\n",
    "fa_results_save_dir = os.path.join(fa_save_dir, 'results')\n",
    "utils.ensure_dir(fa_results_save_dir)\n",
    "\n",
    "# Save dir for R analysis based on factor loading groupings\n",
    "fa_R_input_dir = os.path.join(fa_results_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(fa_R_input_dir)\n",
    "\n",
    "# Save dir for R analysis output based on factor loading groupings\n",
    "fa_R_results_dir = os.path.join(fa_results_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(fa_R_results_dir)\n",
    "\n",
    "# item-level analyses with R save dir\n",
    "item_level_save_dir = os.path.join(ratings_save_dir, 'item_level')\n",
    "utils.ensure_dir(item_level_save_dir)\n",
    "\n",
    "# Attitudes save dir\n",
    "attitudes_save_dir = os.path.join(save_dir, 'attitudes')\n",
    "utils.ensure_dir(attitudes_save_dir)\n",
    "\n",
    "# Attitudes R CSV save dir\n",
    "addit_dv_r_csv_save_dir = os.path.join(attitudes_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(addit_dv_r_csv_save_dir)\n",
    "\n",
    "# Attitudes R results save dir\n",
    "addit_dv_r_result_save_dir = os.path.join(attitudes_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(addit_dv_r_result_save_dir)\n",
    "\n",
    "# Exploratory analysis save dir\n",
    "exploratory_save_dir = os.path.join(save_dir, 'exploratory')\n",
    "\n",
    "# Mentioned/Unmentioned save dir\n",
    "mentioned_save_dir = os.path.join(exploratory_save_dir, 'mentioned_analysis')\n",
    "utils.ensure_dir(mentioned_save_dir)\n",
    "\n",
    "mentioned_R_csv_save_dir = os.path.join(mentioned_save_dir, 'R', 'input_files')\n",
    "utils.ensure_dir(mentioned_R_csv_save_dir)\n",
    "\n",
    "mentioned_R_result_save_dir = os.path.join(mentioned_save_dir, 'R', 'results')\n",
    "utils.ensure_dir(mentioned_R_result_save_dir)\n",
    "\n",
    "# Attitudes Correlations save dir\n",
    "correlation_dir = os.path.join(exploratory_save_dir, 'correlations')\n",
    "utils.ensure_dir(correlation_dir)\n",
    "\n",
    "# Reliability save dir\n",
    "reliability_save_dir = os.path.join(exploratory_save_dir, 'reliability')\n",
    "utils.ensure_dir(reliability_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c2c8d",
   "metadata": {},
   "source": [
    "### Timing Analysis\n",
    "\n",
    "We utilize this information in order to filter out participants who spend too little time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d442b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure to map individual questions to sections of the survey\n",
    "time_mapping = {\n",
    "    'intro': {\n",
    "        'ConsentTime1': 'consent_time',\n",
    "        'PS4': 'screening_time',\n",
    "        'Q10': 'instructions_time',\n",
    "        'Q12': 'check_time',\n",
    "    },\n",
    "    'video': {\n",
    "        # Videos\n",
    "        'Q14': 'mech1_time',\n",
    "        'Q16': 'mech2_time',\n",
    "        'Q18': 'mech3_time',\n",
    "        'Q20': 'func1_time',\n",
    "        'Q22': 'func2_time',\n",
    "        'Q24': 'func3_time',\n",
    "        'Q26': 'intent1_time',\n",
    "        'Q28': 'intent2_time',\n",
    "        'Q30': 'intent3_time',\n",
    "\n",
    "    },\n",
    "    'video_transition': {\n",
    "        # Video -> Survey Transition\n",
    "        'Q32': 'takeaways_time',\n",
    "        'Q34': 'transition_time',\n",
    "    },\n",
    "    'survey': {\n",
    "        # Survey\n",
    "        'Q36': 'survey_time'\n",
    "    },\n",
    "    'post': {\n",
    "        # 'CTime1': 'confidence_time',\n",
    "        'ACTime1': 'attention_check_time',\n",
    "        'DVTime1': 'addit_dvs1_time',\n",
    "        'DVTime2': 'addit_dvs2_time',\n",
    "        'Q42': 'mech_conceptual_time',\n",
    "        'DQTime1': 'demographic_time',\n",
    "        'Q44': 'intent_eos_time',\n",
    "        'Q46': 'eos_time'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_column_mapping = {\n",
    "    'Duration (in seconds)': 'total_time',\n",
    "    'CONDITION': 'condition',\n",
    "    'ResponseId': 'response_id',\n",
    "    'PROLIFIC_PID': 'prolific_id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a67e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_152608] Time analysis exists at ../analysis/timings/time_analysis_all_minutes.csv\n",
      "[0624_152608] Timing statistics exists at ../analysis/timings/timing_stats_all_minutes.csv\n",
      "[0624_152608] Time analysis exists at ../analysis/timings/time_analysis_baseline_minutes.csv\n",
      "[0624_152608] Timing statistics exists at ../analysis/timings/timing_stats_baseline_minutes.csv\n",
      "[0624_152608] Time analysis exists at ../analysis/timings/time_analysis_exp_minutes.csv\n",
      "[0624_152608] Timing statistics exists at ../analysis/timings/timing_stats_exp_minutes.csv\n",
      "Saved file to ../analysis/raw_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Time analysis on all data (baseline + experimental)\n",
    "time_df = analysis.time_analysis(\n",
    "    df=df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='all',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "time_stats_df = analysis.time_stats(\n",
    "    time_df=time_df,\n",
    "    condition='all',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Time analysis on baseline data\n",
    "baseline_time_df = analysis.time_analysis(\n",
    "    df=baseline_df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='baseline',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "baseline_time_stats_df = analysis.time_stats(\n",
    "    time_df=baseline_time_df,\n",
    "    condition='baseline',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Time analysis on experimental data\n",
    "experimental_time_df = analysis.time_analysis(\n",
    "    df=experimental_df,\n",
    "    mapping=time_mapping,\n",
    "    metadata_mapping=metadata_column_mapping,\n",
    "    condition='exp',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "experimental_time_stats_df = analysis.time_stats(\n",
    "    time_df=experimental_time_df,\n",
    "    condition='exp',\n",
    "    save_dir=time_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Append each user's time in raw dataframe\n",
    "if 'survey_time' not in df.columns:\n",
    "    df = pd.concat([df, time_df['survey']], axis=1)\n",
    "    df = df.rename(columns={'survey': 'survey_time'})\n",
    "    df = pd.concat([df, time_df[['median_time_per_survey_page', 'min_time_per_survey_page', 'max_time_per_survey_page']]], axis=1)\n",
    "\n",
    "    utils.informal_log(\"Added time columns to DF ({} rows)\".format(len(df)))\n",
    "raw_df_save_path = os.path.join(save_dir, 'raw_df.csv')\n",
    "utils.write_file(df, raw_df_save_path, overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a569cd",
   "metadata": {},
   "source": [
    "## Perform Exclusions\n",
    "Exclude participants who meet any of the pre-registered criteria:\n",
    "\n",
    "Fail attention check\n",
    "Spend less than 80 second on mental capacity survey\n",
    "Spend less than 1 second per mental capacity question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7fa339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_150535] 476 rows remaining post filtering for minimum of 1.3333 minutes on survey\n",
      "[0624_150535] 476 rows remaining post filtering for minimum median of 0.0167 minutes on each survey page\n",
      "[0624_150535] 470 rows remaining post filtering for post-survey attention check correctness\n",
      "[0624_150535] No manual exclusions performed\n",
      "[0624_150535] Number of rows: 470\n",
      "[0624_150535] Number of rows in novideo (baseline): 118\n",
      "[0624_150535] Number of rows in machines: 116\n",
      "[0624_150535] Number of rows in tools: 119\n",
      "[0624_150535] Number of rows in companions: 117\n",
      "Saved file to ../analysis/mental_capacities/post_exclusion_df.csv\n",
      "[0624_150535] Exclusion parameters already exist at ../analysis/mental_capacities/exclusion_params.json. Meaning this directory contains some exclusion configuration. Save to another directory\n"
     ]
    }
   ],
   "source": [
    "# Get DF post exclusions\n",
    "post_exclusion_df = analysis.perform_exclusions(\n",
    "    df=df,\n",
    "    min_survey_time=min_survey_time,\n",
    "    min_median_per_page_time=min_median_per_page_time,\n",
    "    manual_exclusions=None,\n",
    "    post_attention_check=post_attention_check)\n",
    "\n",
    "exclusion_params = {\n",
    "    'min_survey_time': min_survey_time,\n",
    "    'min_median_per_page_time': min_median_per_page_time,\n",
    "    'n_rows': len(post_exclusion_df)\n",
    "}\n",
    "\n",
    "post_exclusion_df_save_path = os.path.join(ratings_save_dir, 'post_exclusion_df.csv')\n",
    "utils.write_file(post_exclusion_df, post_exclusion_df_save_path, overwrite=overwrite)\n",
    "\n",
    "exclusion_param_save_path = os.path.join(ratings_save_dir, 'exclusion_params.json')\n",
    "if os.path.exists(exclusion_param_save_path):\n",
    "    utils.informal_log(\"Exclusion parameters already exist at {}. Meaning this directory contains some exclusion configuration. Save to another directory\".format(\n",
    "        exclusion_param_save_path\n",
    "    ))\n",
    "else:\n",
    "    utils.write_file(exclusion_params, exclusion_param_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d266d5b",
   "metadata": {},
   "source": [
    "## Demographic Data\n",
    "Obtain demographic data post exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a8107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_145758] Demographics exists at ../analysis/demographics/demographics.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>level</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>25-34</td>\n",
       "      <td>137</td>\n",
       "      <td>29.148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>35-44</td>\n",
       "      <td>119</td>\n",
       "      <td>25.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>45-54</td>\n",
       "      <td>109</td>\n",
       "      <td>23.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>55-64</td>\n",
       "      <td>65</td>\n",
       "      <td>13.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>65+</td>\n",
       "      <td>23</td>\n",
       "      <td>4.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>familiarity_characterai</td>\n",
       "      <td>Heard of it, but never used it</td>\n",
       "      <td>159</td>\n",
       "      <td>33.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>familiarity_characterai</td>\n",
       "      <td>Have used it a few times, but not regularly</td>\n",
       "      <td>20</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>familiarity_characterai</td>\n",
       "      <td>Use 1-2x times a month</td>\n",
       "      <td>6</td>\n",
       "      <td>1.276596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>familiarity_characterai</td>\n",
       "      <td>Use 1-2x a week</td>\n",
       "      <td>2</td>\n",
       "      <td>0.425532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>familiarity_characterai</td>\n",
       "      <td>Use more frequently than 1-2x a week</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   variable                                        level  \\\n",
       "0                       age                                        25-34   \n",
       "1                       age                                        35-44   \n",
       "2                       age                                        45-54   \n",
       "3                       age                                        55-64   \n",
       "4                       age                                          65+   \n",
       "..                      ...                                          ...   \n",
       "88  familiarity_characterai               Heard of it, but never used it   \n",
       "89  familiarity_characterai  Have used it a few times, but not regularly   \n",
       "90  familiarity_characterai                       Use 1-2x times a month   \n",
       "91  familiarity_characterai                              Use 1-2x a week   \n",
       "92  familiarity_characterai         Use more frequently than 1-2x a week   \n",
       "\n",
       "    count    percent  \n",
       "0     137  29.148936  \n",
       "1     119  25.319149  \n",
       "2     109  23.191489  \n",
       "3      65  13.829787  \n",
       "4      23   4.893617  \n",
       "..    ...        ...  \n",
       "88    159  33.829787  \n",
       "89     20   4.255319  \n",
       "90      6   1.276596  \n",
       "91      2   0.425532  \n",
       "92      1   0.212766  \n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_qs = {\n",
    "    'DQ2': 'age',\n",
    "    'DQ3': 'education',\n",
    "    'DQ4': 'gender',\n",
    "    'DQ5': 'race',\n",
    "    'DQ6': 'ethnicity',\n",
    "    'DQ7': 'religion',\n",
    "    'DQ9': 'programming',\n",
    "    'DQ10_1': 'familiarity_chatgpt',\n",
    "    'DQ10_2': 'familiarity_gemini',\n",
    "    'DQ10_3': 'familiarity_claude',\n",
    "    'DQ10_4': 'familiarity_copilot',\n",
    "    'DQ10_5': 'familiarity_replika',\n",
    "    'DQ10_6': 'familiarity_nomi',\n",
    "    'DQ10_7': 'familiarity_characterai'\n",
    "}\n",
    "\n",
    "analysis.get_demographics(\n",
    "    df=post_exclusion_df,\n",
    "    demographic_qs=demographic_qs,\n",
    "    save_dir=demographics_save_dir,\n",
    "    overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5e791",
   "metadata": {},
   "source": [
    "## Clean data to obtain dataframe of ratings\n",
    "Filter out other information besides participant's ratings on each of the 40 mental capacity items, condition, and prolificID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9b459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0624_145832] Ratings exists at ../analysis/mental_capacities/ratings.csv\n",
      "[0624_145832] Rating statistics exists at ../analysis/mental_capacities/statistics/rating_stats.csv\n",
      "[0624_145832] Rating statistics exists at ../analysis/mental_capacities/statistics/novideo_rating_stats.csv\n",
      "[0624_145832] Rating statistics exists at ../analysis/mental_capacities/statistics/machines_rating_stats.csv\n",
      "[0624_145832] Rating statistics exists at ../analysis/mental_capacities/statistics/tools_rating_stats.csv\n",
      "[0624_145832] Rating statistics exists at ../analysis/mental_capacities/statistics/companions_rating_stats.csv\n",
      "[0624_145832] Master ratings exists at ../analysis/mental_capacities/statistics/all_conditions_ratings_stats.csv\n"
     ]
    }
   ],
   "source": [
    "items = utils.read_file(items_path)\n",
    "groupings = utils.read_file(categories_path)\n",
    "n_pages = 40 # Number of survey pages for mental capacity\n",
    "n_items_per_page = 1\n",
    "q_id = 'Q35'\n",
    "n_total = n_pages * n_items_per_page\n",
    "columns = df.columns\n",
    "\n",
    "# MC = mental capacity\n",
    "mc_mapping = analysis.get_mc_mapping(\n",
    "    items=items,\n",
    "    n_pages=n_pages,\n",
    "    n_items_per_page=n_items_per_page,\n",
    "    q_id=q_id,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# Make dataframe of ratings (rows = participants; columns = mental states)\n",
    "rating_df = analysis.get_ratings(\n",
    "    df=post_exclusion_df,\n",
    "    mc_mapping=mc_mapping,\n",
    "    groupings=groupings,\n",
    "    n_total=n_total,\n",
    "    save_dir=ratings_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Get mean (and std) ratings of each mental state in separate dataframes for each condition\n",
    "stats_dfs = analysis.mean_ratings(\n",
    "    rating_df=rating_df,\n",
    "    conditions=conditions,\n",
    "    save_conditions=True,\n",
    "    save_dir=rating_stats_save_dir,\n",
    "    overwrite=overwrite)\n",
    "\n",
    "# Combine list of stats for each condition into one large DF\n",
    "master_stats = analysis.create_master_stats(\n",
    "    stats_dfs=stats_dfs,\n",
    "    save_dir=rating_stats_save_dir,\n",
    "    overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939624df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiexhibit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
